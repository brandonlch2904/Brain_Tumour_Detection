{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyP8fiUVx+56OIsiJK52YIEU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Setting Up Environment\n","\n","\n"],"metadata":{"id":"Lvl46cWpA2Cj"}},{"cell_type":"markdown","source":["## a. Installing Dependencies\n"],"metadata":{"id":"s1kVZmEO_lPC"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJA19BaG_b4w","executionInfo":{"status":"ok","timestamp":1752736746485,"user_tz":-480,"elapsed":13114,"user":{"displayName":"FYP","userId":"06650288711143266396"}},"outputId":"712fe723-d489-4690-ef70-c10e45db9342"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.7.14)\n","Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n","Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n","Requirement already satisfied: pillow-heif<2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.5.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n"]}],"source":["# PyTorch & Torchvision\n","!pip install --quiet torch torchvision torchaudio\n","\n","# Roboflow for dataset\n","!pip install roboflow\n","\n","# Optuna for Hyperparameter Optimization\n","!pip install optuna"]},{"cell_type":"markdown","source":["## b. Importing Libraries\n"],"metadata":{"id":"6l6McncgAAuB"}},{"cell_type":"code","source":["from roboflow import Roboflow\n","import os\n","import torch\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import torchvision.transforms as T\n","from torchvision import models\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import (\n","    confusion_matrix,\n","    precision_recall_curve,\n","    classification_report,\n","    roc_curve,\n","    auc\n",")\n","from sklearn.preprocessing import label_binarize\n","import optuna\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from time import perf_counter"],"metadata":{"id":"95yRcOjlAQf1","executionInfo":{"status":"ok","timestamp":1752736746490,"user_tz":-480,"elapsed":6,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## c. Download Dataset and Mount Drive"],"metadata":{"id":"w0iR9yvWAJ1R"}},{"cell_type":"code","source":["# Download Dataset\n","rf = Roboflow(api_key=\"SOWkZCal2FAKPG56WSnb\")\n","project = rf.workspace(\"work-tqclg\").project(\"tumor-cjxoh\")\n","version = project.version(1)\n","dataset = version.download(\"multiclass\", location=\"data\")\n","\n","# Mounting Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7hkPuQkAEHV","executionInfo":{"status":"ok","timestamp":1752736781751,"user_tz":-480,"elapsed":35260,"user":{"displayName":"FYP","userId":"06650288711143266396"}},"outputId":"6eb7efb7-b79a-4569-b444-e11d32524e31"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# 2. Model Training"],"metadata":{"id":"5-CZMFpSBCOb"}},{"cell_type":"markdown","source":["## a. Global Training Configuration"],"metadata":{"id":"zbRUiNMAD5NX"}},{"cell_type":"code","source":["DATA_DIR      = 'data'\n","TRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train')\n","VALID_IMG_DIR = os.path.join(DATA_DIR, 'valid')\n","TEST_IMG_DIR  = os.path.join(DATA_DIR, 'test')\n","TRAIN_CSV     = os.path.join(TRAIN_IMG_DIR, '_classes.csv')\n","VALID_CSV     = os.path.join(VALID_IMG_DIR, '_classes.csv')\n","TEST_CSV      = os.path.join(TEST_IMG_DIR, '_classes.csv')\n","\n","BATCH_SIZE    = 32\n","MAX_EPOCHS    = 30\n","PATIENCE      = 5\n","\n","LR            = 1e-4\n","WEIGHT_DECAY  = 1e-3\n","STEP_SIZE     = 5\n","GAMMA         = 0.1\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","base_dir = \"/content/drive/MyDrive/Brandon's FYP\"\n","os.makedirs(base_dir, exist_ok=True)\n","OPTIMIZED_HYPERPARAMETERS = \"/content/drive/MyDrive/Brandon's FYP/Hyperparameter Optimization.xlsx\""],"metadata":{"id":"19bbK3WYC11z","executionInfo":{"status":"ok","timestamp":1752736782056,"user_tz":-480,"elapsed":208,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## b. Model Loader"],"metadata":{"id":"XIF6BQHkEHO2"}},{"cell_type":"code","source":["def get_all_models(num_classes):\n","    models_list = []\n","\n","    # ResNet50\n","    resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n","    resnet.fc = torch.nn.Sequential(\n","        torch.nn.Dropout(0.5),\n","        torch.nn.Linear(resnet.fc.in_features, num_classes)\n","    )\n","    models_list.append((\"ResNet50\", resnet))\n","\n","    # EfficientNetB2\n","    effnet = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.IMAGENET1K_V1)\n","    effnet.classifier[1] = torch.nn.Linear(effnet.classifier[1].in_features, num_classes)\n","    models_list.append((\"EfficientNetB2\", effnet))\n","\n","    # MobileNetV3\n","    mobile = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n","    mobile.classifier[3] = torch.nn.Linear(mobile.classifier[3].in_features, num_classes)\n","    models_list.append((\"MobileNetV3\", mobile))\n","\n","    return models_list\n"],"metadata":{"id":"Apkgs2HbEEr5","executionInfo":{"status":"ok","timestamp":1752736782084,"user_tz":-480,"elapsed":26,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## c. Dataset Class"],"metadata":{"id":"jKd5yCWXGdUo"}},{"cell_type":"code","source":["# ----------------------------\n","# Custom Dataset Class from CSV\n","# ----------------------------\n","class CSVClassificationDataset(torch.utils.data.Dataset):\n","    def __init__(self, csv_file, img_dir, transform=None):\n","        self.img_dir   = img_dir\n","        self.transform = transform\n","\n","        # Load CSV and infer class columns\n","        df = pd.read_csv(csv_file)\n","        df.columns = df.columns.str.strip()  # Clean column names\n","        self.class_names = [c for c in df.columns if c.lower() != 'filename']\n","        self.num_classes = len(self.class_names)\n","\n","        self.samples = [\n","            (row['filename'], int(np.argmax(row[self.class_names].values.astype(int))))\n","            for _, row in df.iterrows()\n","        ]\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        fname, label = self.samples[idx]\n","        img_path = os.path.join(self.img_dir, fname)\n","        img = Image.open(img_path).convert(\"RGB\")\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, torch.tensor(label, dtype=torch.long)"],"metadata":{"id":"dzig--8nGhE9","executionInfo":{"status":"ok","timestamp":1752736782102,"user_tz":-480,"elapsed":8,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## d. Data Preprocessing (Transformer)"],"metadata":{"id":"PNpJtjvzEmzJ"}},{"cell_type":"code","source":["# ----------------------------\n","# Flexible Preprocessing Function\n","# mode = 0 → Baseline (resize + normalize only)\n","# mode = 1 → Enhanced (blur, jitter, flip, rotate, normalize)\n","# ----------------------------\n","class GaussianBlur:\n","    def __init__(self, kernel_size=3):\n","        self.kernel_size = kernel_size if kernel_size % 2 == 1 else kernel_size + 1\n","\n","    def __call__(self, img):\n","        img_np = np.array(img)\n","        blurred = cv2.GaussianBlur(img_np, (self.kernel_size, self.kernel_size), 0)\n","        return Image.fromarray(blurred)\n","\n","def get_transforms(mode=0):\n","    # ImageNet Normalization\n","    normalize = T.Normalize([0.485, 0.456, 0.406],\n","                            [0.229, 0.224, 0.225])\n","\n","    if mode == 0:\n","        # Baseline: Resize + Normalize\n","        train_transform = T.Compose([\n","            T.Resize((224, 224)),\n","            T.ToTensor(),\n","            normalize,\n","        ])\n","        val_transform = train_transform\n","\n","    else:\n","        # Stage 2\n","        train_transform = T.Compose([\n","            T.Resize((224, 224)),      # (1) Resize first\n","            T.RandomHorizontalFlip(),  # (2) Flip\n","            T.RandomRotation(15),      # (3) Rotate ±15°\n","            T.ColorJitter(\n","                brightness=0.1,   # ±10%\n","                contrast=0.1,     # ±10%\n","                saturation=0.1,   # ±10%\n","                hue=0.05          # ±5%\n","            ),\n","            T.RandomApply(\n","                [GaussianBlur(kernel_size=3)],  # (5) Small blur on only some images\n","                p=0.3\n","            ),\n","            T.ToTensor(),\n","            normalize,\n","        ])\n","\n","        val_transform = T.Compose([\n","            T.Resize((224, 224)),\n","            T.ToTensor(),\n","            normalize,\n","        ])\n","\n","    return train_transform, val_transform\n"],"metadata":{"id":"kq7zDmk1EuHX","executionInfo":{"status":"ok","timestamp":1752736782237,"user_tz":-480,"elapsed":133,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## e. Main Training Function"],"metadata":{"id":"GVoogvb5Ec5X"}},{"cell_type":"code","source":["# ----------------------------\n","# Evaluation Function\n","# ----------------------------\n","def evaluate(model, loader, device):\n","    model.eval()\n","    correct = total = 0\n","    with torch.no_grad():\n","        for imgs, labels in loader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            preds = torch.argmax(model(imgs), dim=1)\n","            correct += (preds == labels).sum().item()\n","            total   += labels.size(0)\n","    return correct / total\n","\n","# ----------------------------\n","# Train Function\n","# ----------------------------\n","def train_model(model, model_name, train_loader, val_loader, custom_config=None):\n","    # Use global constants or override with custom config\n","    lr           = custom_config['lr']           if custom_config else LR\n","    weight_decay = custom_config['weight_decay'] if custom_config else WEIGHT_DECAY\n","    optimizer_type = custom_config['optimizer']  if custom_config else 'sgd'\n","    if optimizer_type == 'sgd':\n","        momentum = custom_config.get('momentum', 0.9)\n","    else:\n","        momentum = None\n","    scheduler_type = custom_config['scheduler'] if custom_config else 'steplr'\n","\n","    # Define model-specific directory under base_dir\n","    model_root_dir = os.path.join(base_dir, model_name)\n","    version = 1\n","    save_dir = os.path.join(model_root_dir, f\"run_v{version}\")\n","    while os.path.exists(save_dir):\n","        version += 1\n","        save_dir = os.path.join(model_root_dir, f\"run_v{version}\")\n","    os.makedirs(save_dir, exist_ok=True)\n","    print(f\"[{model_name}] Saving checkpoints & plots to: {save_dir}\")\n","\n","    # Move model to device\n","    model = model.to(DEVICE)\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","    # Optimizer\n","    if optimizer_type == 'adam':\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    else:\n","        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n","\n","    # Scheduler\n","    if scheduler_type == 'cosineannealing':\n","        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCHS)\n","    elif scheduler_type == 'steplr':\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","    else:\n","        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1.0)\n","\n","    # Training loop\n","    best_acc = 0.0\n","    train_losses = []\n","    val_accuracies = []\n","    epochs_no_improve = 0\n","\n","    print(f\"\\n--- Starts Training: {model_name} ---\")\n","    for epoch in range(1, MAX_EPOCHS + 1):\n","        model.train()\n","        running_loss = 0.0\n","\n","        for imgs, labels in train_loader:\n","            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n","            optimizer.zero_grad()\n","            loss = criterion(model(imgs), labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        scheduler.step()\n","\n","        avg_loss = running_loss / len(train_loader)\n","        train_losses.append(avg_loss)\n","\n","        acc = evaluate(model, val_loader, DEVICE)\n","        val_accuracies.append(acc)\n","\n","        if acc > best_acc:\n","            best_acc = acc\n","            epochs_no_improve = 0\n","            torch.save(model.state_dict(), os.path.join(save_dir, 'best.pth'))\n","            print(f\"[{model_name}] Epoch {epoch:02d}: ⬆ New best val_acc: {acc:.4f} | Train Loss: {avg_loss:.4f}\")\n","        else:\n","            epochs_no_improve += 1\n","            print(f\"[{model_name}] Epoch {epoch:02d}: — val_acc did not improve ({acc:.4f}); \"\n","                  f\"patience {epochs_no_improve}/{PATIENCE} | Train Loss: {avg_loss:.4f}\")\n","\n","        torch.save(model.state_dict(), os.path.join(save_dir, 'last.pth'))\n","\n","        if epochs_no_improve >= PATIENCE:\n","            print(f\"Early stopping triggered for {model_name}\")\n","            break\n","\n","    # Plot loss and accuracy\n","    epochs_range = range(1, len(train_losses) + 1)\n","\n","    plt.figure()\n","    plt.plot(epochs_range, train_losses, 'o-', label=\"Train Loss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(f\"{model_name} Loss Curve\")\n","    plt.legend(); plt.grid()\n","    plt.savefig(os.path.join(save_dir, \"loss_curve.png\")); plt.close()\n","\n","    plt.figure()\n","    plt.plot(epochs_range, val_accuracies, 's-', label=\"Val Accuracy\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.title(f\"{model_name} Accuracy Curve\")\n","    plt.legend(); plt.grid()\n","    plt.savefig(os.path.join(save_dir, \"val_accuracy_curve.png\")); plt.close()\n"],"metadata":{"id":"Fq_rqw9sEfeh","executionInfo":{"status":"ok","timestamp":1752736782257,"user_tz":-480,"elapsed":8,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## f. Stage Training Functions"],"metadata":{"id":"sKTUzrx3JFbB"}},{"cell_type":"code","source":["# ----------------------------\n","# Stage 1: Baseline Training\n","# ----------------------------\n","def stage_1_baseline_training():\n","    print(\"\\n==== Stage 1: Baseline Training ====\\n\")\n","\n","    # Get transforms for Stage 1 (mode=0)\n","    train_transform, val_transform = get_transforms(mode=0)\n","\n","    # Create datasets and data loaders\n","    train_ds = CSVClassificationDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_transform)\n","    val_ds   = CSVClassificationDataset(VALID_CSV, VALID_IMG_DIR, transform=val_transform)\n","\n","    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n","    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","    # Get all models\n","    models_list = get_all_models(num_classes=train_ds.num_classes)\n","\n","    # Loop through models and train each one\n","    for model_name, model in models_list:\n","        print(f\"\\n--- Training {model_name} ---\")\n","        train_model(model, model_name, train_loader, val_loader)\n","\n","# ----------------------------\n","# Stage 2: Preprocessing + Augmentation Training\n","# ----------------------------\n","def stage_2_preprocessing_training():\n","    print(\"\\n==== Stage 2: Training with Preprocessing & Augmentation ====\\n\")\n","\n","    # Get enhanced transforms (mode=1)\n","    train_transform, val_transform = get_transforms(mode=1)\n","\n","    # Prepare datasets and loaders\n","    train_ds = CSVClassificationDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_transform)\n","    val_ds   = CSVClassificationDataset(VALID_CSV, VALID_IMG_DIR, transform=val_transform)\n","\n","    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n","    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","    # Load models\n","    models_list = get_all_models(num_classes=train_ds.num_classes)\n","\n","    # Train each model\n","    for model_name, model in models_list:\n","        print(f\"\\n--- Stage 2 Training: {model_name} ---\")\n","        train_model(model, model_name, train_loader, val_loader)\n","\n","# ----------------------------\n","# Stage 3: Hyperparameter Optimization with Optuna (n_trials per model)\n","# ----------------------------\n","def stage_3_hyperparameter_optimization(n_trials=20):\n","    print(f\"\\n==== Stage 3: Hyperparameter Search ({n_trials} trials per model) ====\\n\")\n","\n","    def objective_for_model(fixed_model_name, trial):\n","        # 1. Sample hyperparameters (excluding model_name, which is fixed)\n","        lr           = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n","        batch_size   = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n","        weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n","        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n","        optimizer    = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\"])\n","        scheduler    = trial.suggest_categorical(\"scheduler\", [\"none\", \"steplr\", \"cosineannealing\"])\n","\n","        # Print trial info\n","        print(f\"\\n--- {fixed_model_name} Trial {trial.number + 1}/{n_trials} ---\")\n","        print(f\"LR: {lr:.2e} | Batch: {batch_size} | WD: {weight_decay:.2e} | \"\n","              f\"Dropout: {dropout_rate:.2f} | Opt: {optimizer} | Momentum: {momentum:.2f} | Scheduler: {scheduler}\")\n","\n","        # 2. Build DataLoaders with stage 3 transforms\n","        train_transform, val_transform = get_transforms(mode=1)\n","        train_ds = CSVClassificationDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_transform)\n","        val_ds   = CSVClassificationDataset(VALID_CSV, VALID_IMG_DIR, transform=val_transform)\n","\n","        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2)\n","        val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","        # 3. Instantiate fixed_model_name from get_all_models and replace dropout\n","        models_list = get_all_models(train_ds.num_classes)\n","        model = None\n","        for name, m in models_list:\n","            if name == fixed_model_name:\n","                if fixed_model_name == \"ResNet50\":\n","                    m.fc[0] = torch.nn.Dropout(dropout_rate)\n","                elif fixed_model_name == \"EfficientNetB2\":\n","                    m.classifier.insert(0, torch.nn.Dropout(dropout_rate))\n","                elif fixed_model_name == \"MobileNetV3\":\n","                    m.classifier.insert(0, torch.nn.Dropout(dropout_rate))\n","                model = m.to(DEVICE)\n","                break\n","\n","        # 4. Choose optimizer\n","        if optimizer == \"sgd\":\n","            momentum     = trial.suggest_float(\"momentum\", 0.5, 0.99)\n","            optim_inst = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n","        else:\n","            optim_inst = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","        # 5. Choose scheduler\n","        if scheduler == \"steplr\":\n","            scheduler_inst = optim.lr_scheduler.StepLR(optim_inst, step_size=5, gamma=0.1)\n","        elif scheduler == \"cosineannealing\":\n","            scheduler_inst = optim.lr_scheduler.CosineAnnealingLR(optim_inst, T_max=10)\n","        else:\n","            scheduler_inst = None\n","\n","        criterion = nn.CrossEntropyLoss()\n","        best_val_acc = 0.0\n","\n","        # 6. Train for fixed 10 epochs per trial\n","        for epoch in range(10):\n","            model.train()\n","            for imgs, labels in train_loader:\n","                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n","                optim_inst.zero_grad()\n","                outputs = model(imgs)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optim_inst.step()\n","\n","            if scheduler_inst:\n","                scheduler_inst.step()\n","\n","            # 7. Validation\n","            model.eval()\n","            correct = 0\n","            total = 0\n","            with torch.no_grad():\n","                for imgs, labels in val_loader:\n","                    imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n","                    outputs = model(imgs)\n","                    preds = outputs.argmax(dim=1)\n","                    correct += (preds == labels).sum().item()\n","                    total += labels.size(0)\n","            val_acc = correct / total\n","\n","            # Print epoch progress\n","            print(f\"{fixed_model_name} Trial {trial.number + 1}, Epoch {epoch + 1}/10, Val Acc: {val_acc:.4f}\")\n","\n","            trial.report(val_acc, epoch)\n","            if trial.should_prune():\n","                print(f\"{fixed_model_name} Trial {trial.number + 1} pruned at epoch {epoch + 1}\")\n","                raise optuna.TrialPruned()\n","\n","            best_val_acc = max(best_val_acc, val_acc)\n","\n","        return best_val_acc\n","\n","    # 8. Loop over each model, run n_trials per model\n","    all_best_configs = []\n","    for fixed_model_name in [\"ResNet50\", \"EfficientNetB2\", \"MobileNetV3\"]:\n","        print(f\"\\n===== Optimizing {fixed_model_name} =====\")\n","        study = optuna.create_study(direction=\"maximize\")\n","        func = lambda trial: objective_for_model(fixed_model_name, trial)\n","        study.optimize(func, n_trials=n_trials)\n","\n","        # 9. Extract top 3 configs for this model\n","        df_trials = study.trials_dataframe()\n","        # Tag every trial with fixed_model_name, since this study only tuned that model\n","        df_trials[\"model\"] = fixed_model_name\n","        # Sort all trials by “value” and take the top 3\n","        df_m_sorted = df_trials.sort_values(\"value\", ascending=False).head(3)\n","\n","        for rank, row in enumerate(df_m_sorted.itertuples(), start=1):\n","            all_best_configs.append({\n","                \"model\":        row.model,  # same as fixed_model_name\n","                \"rank\":         rank,\n","                \"learning_rate\": row.params_learning_rate,\n","                \"batch_size\":    row.params_batch_size,\n","                \"weight_decay\":  row.params_weight_decay,\n","                \"dropout_rate\":  row.params_dropout_rate,\n","                \"optimizer\":     row.params_optimizer,\n","                \"momentum\":      row.params_momentum,\n","                \"scheduler\":     row.params_scheduler,\n","                \"val_accuracy\":  row.value\n","            })\n","\n","    # 10. Save all results to CSV\n","    df_best = pd.DataFrame(all_best_configs)\n","    df_best = df_best[[\n","        \"model\", \"rank\", \"learning_rate\", \"batch_size\", \"weight_decay\",\n","        \"dropout_rate\", \"optimizer\", \"momentum\", \"scheduler\", \"val_accuracy\"\n","    ]]\n","    summary_path = \"/content/drive/MyDrive/Brandon's FYP/hparam_stage3_summary.csv\"\n","    df_best.to_csv(summary_path, index=False)\n","\n","    print(\"\\n=== Top 3 Configurations per Model ===\")\n","    print(df_best)\n","    print(f\"\\nSummary saved to: {summary_path}\")\n","\n","    # -----------------------------------------------------------------------------\n","# Stage 3 – Train each model on its best (rank-1) configuration\n","# -----------------------------------------------------------------------------\n","\n","# Best Configs from “Rank 1” table\n","BEST_CONFIGS = {\n","    'ResNet50': {\n","        'lr':           9.71211e-05,\n","        'batch_size':  16,\n","        'weight_decay':7.01183e-05,\n","        'dropout':     0.40369264,\n","        'optimizer':   'adam',\n","        'momentum':    None,\n","        'scheduler':   'cosineannealing',\n","    },\n","    'EfficientNetB2': {\n","        'lr':           0.0000612861,\n","        'batch_size':  64,\n","        'weight_decay':5.97754e-06,\n","        'dropout':     0.358457194,\n","        'optimizer':   'adam',\n","        'momentum':    None,\n","        'scheduler':   'cosineannealing',\n","    },\n","    'MobileNetV3': {\n","        'lr':           3.05e-04,\n","        'batch_size':  16,\n","        'weight_decay':6.14e-05,\n","        'dropout':     0.227504223,\n","        'optimizer':   'adam',\n","        'momentum':    None,\n","        'scheduler':   'steplr',\n","    },\n","}\n","\n","# ----------------------------\n","# Stage 3 Training Function with Best Config\n","# ----------------------------\n","def stage_3_best_config_training():\n","    print(\"\\n==== Stage 3: Training on Best Configurations ====\\n\")\n","\n","    # Get transforms for Stage 1 (mode=0 for fair comparison)\n","    train_transform, val_transform = get_transforms(mode=0)\n","\n","    # Create datasets and data loaders (we'll customize batch size later per model)\n","    train_ds = CSVClassificationDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_transform)\n","    val_ds   = CSVClassificationDataset(VALID_CSV, VALID_IMG_DIR, transform=val_transform)\n","\n","    # Load all models\n","    models_list = get_all_models(num_classes=train_ds.num_classes)\n","\n","    for model_name, model in models_list:\n","        print(f\"\\n--- Training {model_name} on Best Configuration ---\")\n","\n","        # Get best config for this model\n","        config = BEST_CONFIGS[model_name]\n","\n","        # Update dropout layer dynamically before training\n","        dropout = config['dropout']\n","        if model_name == 'ResNet50':\n","            in_features = model.fc[1].in_features\n","            out_features = model.fc[1].out_features\n","            model.fc = torch.nn.Sequential(\n","                torch.nn.Dropout(dropout),\n","                torch.nn.Linear(in_features, out_features)\n","            )\n","        elif model_name == 'EfficientNetB2':\n","            in_features = model.classifier[1].in_features\n","            out_features = model.classifier[1].out_features\n","            model.classifier = torch.nn.Sequential(\n","                torch.nn.Dropout(dropout),\n","                torch.nn.Linear(in_features, out_features)\n","            )\n","        elif model_name == 'MobileNetV3':\n","            m = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n","            # insert dropout before the final layer\n","            m.classifier[2] = nn.Dropout(config[\"dropout\"])\n","            # replace only the final linear\n","            in_f = m.classifier[3].in_features\n","            m.classifier[3] = nn.Linear(in_f, 4)\n","\n","        # Create data loaders using model-specific batch size\n","        batch_size = config['batch_size']\n","        train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True,  num_workers=2)\n","        val_loader   = DataLoader(val_ds,   batch_size=config['batch_size'], shuffle=False, num_workers=2)\n","\n","        # Train with injected config\n","        train_model(model, model_name, train_loader, val_loader, custom_config=config)"],"metadata":{"id":"OTxNwtV8JET9","executionInfo":{"status":"ok","timestamp":1752740689007,"user_tz":-480,"elapsed":62,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Main Training Launcher"],"metadata":{"id":"yid6Ue3DIDZv"}},{"cell_type":"code","source":["# ----------------------------\n","# Main Launcher\n","# ----------------------------\n","if __name__ == '__main__':\n","    # stage_1_baseline_training()\n","    # stage_2_preprocessing_training()\n","    # stage_3_hyperparameter_optimization(n_trials=20) # 9 hours, 49 minutes\n","    stage_3_best_config_training()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0Iu9tpCICgj","outputId":"41e9fdf0-4146-478e-c1b7-48f386f9852b","executionInfo":{"status":"ok","timestamp":1752741858452,"user_tz":-480,"elapsed":1164993,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==== Stage 3: Training on Best Configurations ====\n","\n","\n","--- Training MobileNetV3 on Best Configuration ---\n","[MobileNetV3] Saving checkpoints & plots to: /content/drive/MyDrive/Brandon's FYP/MobileNetV3/run_v4\n","\n","--- Starts Training: MobileNetV3 ---\n","[MobileNetV3] Epoch 01: ⬆ New best val_acc: 0.9555 | Train Loss: 0.1827\n","[MobileNetV3] Epoch 02: ⬆ New best val_acc: 0.9682 | Train Loss: 0.0561\n","[MobileNetV3] Epoch 03: ⬆ New best val_acc: 0.9734 | Train Loss: 0.0369\n","[MobileNetV3] Epoch 04: — val_acc did not improve (0.9612); patience 1/5 | Train Loss: 0.0371\n","[MobileNetV3] Epoch 05: — val_acc did not improve (0.9612); patience 2/5 | Train Loss: 0.0276\n","[MobileNetV3] Epoch 06: ⬆ New best val_acc: 0.9859 | Train Loss: 0.0060\n","[MobileNetV3] Epoch 07: — val_acc did not improve (0.9859); patience 1/5 | Train Loss: 0.0019\n","[MobileNetV3] Epoch 08: ⬆ New best val_acc: 0.9872 | Train Loss: 0.0015\n","[MobileNetV3] Epoch 09: — val_acc did not improve (0.9872); patience 1/5 | Train Loss: 0.0010\n","[MobileNetV3] Epoch 10: — val_acc did not improve (0.9867); patience 2/5 | Train Loss: 0.0007\n","[MobileNetV3] Epoch 11: — val_acc did not improve (0.9870); patience 3/5 | Train Loss: 0.0006\n","[MobileNetV3] Epoch 12: — val_acc did not improve (0.9872); patience 4/5 | Train Loss: 0.0013\n","[MobileNetV3] Epoch 13: ⬆ New best val_acc: 0.9886 | Train Loss: 0.0009\n","[MobileNetV3] Epoch 14: — val_acc did not improve (0.9875); patience 1/5 | Train Loss: 0.0005\n","[MobileNetV3] Epoch 15: — val_acc did not improve (0.9870); patience 2/5 | Train Loss: 0.0004\n","[MobileNetV3] Epoch 16: — val_acc did not improve (0.9878); patience 3/5 | Train Loss: 0.0006\n","[MobileNetV3] Epoch 17: — val_acc did not improve (0.9883); patience 4/5 | Train Loss: 0.0006\n","[MobileNetV3] Epoch 18: — val_acc did not improve (0.9881); patience 5/5 | Train Loss: 0.0009\n","Early stopping triggered for MobileNetV3\n"]}]},{"cell_type":"markdown","source":["# 3. Model Testing"],"metadata":{"id":"Il29TupBBG-t"}},{"cell_type":"markdown","source":["## a. Model Evaluation Function\n","\n","\n"],"metadata":{"id":"QJ3_cP2XKcy-"}},{"cell_type":"code","source":["def evaluate_model(model_name, run_version, model_filename):\n","    print(f\"\\n--- Evaluating {model_name} ({run_version}) ---\")\n","\n","    # --- Config & paths ---\n","    DEVICE     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    BASE_DIR   = \"/content/drive/MyDrive/Brandon's FYP\"\n","    MODEL_PATH = os.path.join(BASE_DIR, model_name, run_version, model_filename)\n","    SAVE_DIR   = os.path.dirname(MODEL_PATH)\n","    TEST_IMG_DIR = \"data/test\"\n","    TEST_CSV     = os.path.join(TEST_IMG_DIR, \"_classes.csv\")\n","    os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","    # --- Load CSV and prepare classes ---\n","    df = pd.read_csv(TEST_CSV)\n","    df.columns = df.columns.str.strip()\n","    class_cols = [c for c in df.columns if c != 'filename']\n","    NUM_CLASSES = len(class_cols)\n","\n","    # --- Load model architecture and weights ---\n","    models_dict = dict(get_all_models(NUM_CLASSES))\n","    model = models_dict[model_name]\n","    state = torch.load(MODEL_PATH, map_location=DEVICE)\n","    model.load_state_dict(state)\n","    model = model.to(DEVICE)\n","    model.eval()\n","\n","    # --- Transforms (match validation pipeline) ---\n","    transform = T.Compose([\n","        T.Resize((224,224)),\n","        T.ToTensor(),\n","        T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n","    ])\n","\n","    # --- Inference loop ---\n","    y_true, y_pred, y_prob = [], [], []\n","    with torch.no_grad():\n","        for _, row in df.iterrows():\n","            img_path = os.path.join(TEST_IMG_DIR, row['filename'].strip())\n","            img = Image.open(img_path).convert(\"RGB\")\n","            x   = transform(img).unsqueeze(0).to(DEVICE)\n","            logits = model(x)\n","            probs  = torch.softmax(logits, dim=1).cpu().numpy()[0]\n","            pred   = int(np.argmax(probs))\n","            true   = int(row[class_cols].astype(int).values.argmax())\n","            y_true.append(true)\n","            y_pred.append(pred)\n","            y_prob.append(probs)\n","    y_prob = np.array(y_prob)\n","\n","    # --- Confusion Matrix ---\n","    cm = confusion_matrix(y_true, y_pred)\n","    cm_norm = cm.astype(float) / cm.sum(axis=1)[:, None]\n","    def plot_cm(matrix, title, fname, norm=False):\n","        fig, ax = plt.subplots()\n","        im = ax.imshow(matrix, cmap='Blues', vmin=0 if norm else None, vmax=1 if norm else None)\n","        plt.colorbar(im, ax=ax)\n","        ax.set(xticks=np.arange(NUM_CLASSES), yticks=np.arange(NUM_CLASSES),\n","               xticklabels=class_cols, yticklabels=class_cols,\n","               xlabel='Predicted', ylabel='Actual', title=title)\n","        for i in range(NUM_CLASSES):\n","            for j in range(NUM_CLASSES):\n","                value = f\"{matrix[i,j]:.2f}\" if norm else str(matrix[i,j])\n","                ax.text(j, i, value, ha='center', va='center',\n","                        color='white' if matrix[i,j] > matrix.max()/2. else 'black')\n","        fig.tight_layout()\n","        fig.savefig(os.path.join(SAVE_DIR, fname), dpi=150)\n","        plt.close(fig)\n","    plot_cm(cm, f'{model_name}: Confusion Matrix', 'confusion_matrix.png')\n","    plot_cm(cm_norm, f'{model_name}: Normalized Confusion Matrix', 'confusion_matrix_normalized.png', norm=True)\n","\n","    # --- F1 Curve ---\n","    common_t = np.linspace(0,1,100)\n","    f1_curves = []\n","    for idx, cls in enumerate(class_cols):\n","        yb      = np.array(y_true) == idx\n","        scores  = y_prob[:, idx]\n","        prec, rec, th = precision_recall_curve(yb, scores)\n","        f1_vals = 2 * prec * rec / (prec + rec + 1e-8)\n","        th_ext  = np.concatenate(([0], th))\n","        f1_curves.append(np.interp(common_t, th_ext, f1_vals))\n","    mean_f1 = np.mean(f1_curves, axis=0)\n","    fig, ax = plt.subplots()\n","    for idx, cls in enumerate(class_cols):\n","        ax.plot(common_t, f1_curves[idx], label=cls)\n","    ax.plot(common_t, mean_f1, 'k--', lw=2, label='Average')\n","    ax.set(title=f'{model_name}: F1 Score vs. Threshold', xlabel='Threshold', ylabel='F1 Score')\n","    ax.legend(loc='lower left', fontsize='small')\n","    fig.tight_layout()\n","    fig.savefig(os.path.join(SAVE_DIR, 'f1_curve.png'), dpi=150)\n","    plt.close(fig)\n","\n","    # --- ROC Curve ---\n","    y_true_bin = label_binarize(y_true, classes=list(range(NUM_CLASSES)))\n","    fpr, tpr, roc_auc = {}, {}, {}\n","    for i in range(NUM_CLASSES):\n","        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","    fig, ax = plt.subplots()\n","    for i, cls in enumerate(class_cols):\n","        ax.plot(fpr[i], tpr[i], label=f'{cls} (AUC = {roc_auc[i]:.2f})')\n","    ax.plot([0,1], [0,1], 'k--', linewidth=1)\n","    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate',\n","           title=f'{model_name}: ROC Curves (OvR)')\n","    ax.legend(loc='lower right', fontsize='small')\n","    fig.tight_layout()\n","    fig.savefig(os.path.join(SAVE_DIR, 'roc_curve.png'), dpi=150)\n","    plt.close(fig)\n","\n","    # --- Classification Report ---\n","    report = classification_report(y_true, y_pred, target_names=class_cols, output_dict=True, zero_division=0)\n","    df_report = pd.DataFrame(report).T\n","    df_report.to_csv(os.path.join(SAVE_DIR, 'classification_report.csv'))\n","\n","    fig, ax = plt.subplots(figsize=(8, 1 + 0.5*len(df_report)))\n","    ax.axis('off')\n","    tbl = ax.table(\n","        cellText=np.round(df_report.values, 3),\n","        rowLabels=df_report.index,\n","        colLabels=df_report.columns,\n","        cellLoc='center', loc='center'\n","    )\n","    tbl.auto_set_font_size(False)\n","    tbl.set_fontsize(10)\n","    tbl.scale(1, 1.5)\n","    plt.title(f'{model_name}: Classification Report', pad=20)\n","    fig.tight_layout()\n","    fig.savefig(os.path.join(SAVE_DIR, 'classification_report.png'), dpi=150)\n","    plt.close(fig)\n","\n","    print(f\"✅ Saved all evaluation outputs for {model_name} to:\\n → {SAVE_DIR}\")"],"metadata":{"id":"x9HRlZR9KgKC","executionInfo":{"status":"ok","timestamp":1752741883860,"user_tz":-480,"elapsed":10,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## b. CPU Timing Function"],"metadata":{"id":"IHhOfbEO2vzn"}},{"cell_type":"code","source":["def measure_cpu_inference_time(\n","    model_name,\n","    run_version,\n","    model_filename,\n","    batch_size=BATCH_SIZE,\n","    device=torch.device(\"cpu\")\n","):\n","    print(f\"\\n--- CPU Inference Timing: {model_name} ({run_version}) ---\")\n","\n","    # Paths\n","    BASE_DIR     = \"/content/drive/MyDrive/Brandon's FYP\"\n","    MODEL_PATH   = os.path.join(BASE_DIR, model_name, run_version, model_filename)\n","    SAVE_DIR     = os.path.dirname(MODEL_PATH)\n","    TEST_IMG_DIR = \"data/test\"\n","    TEST_CSV     = os.path.join(TEST_IMG_DIR, \"_classes.csv\")\n","    os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","    # Load test dataset using existing transforms and loader\n","    print(f\"Loading test set from {TEST_CSV}\")\n","    _, val_transform = get_transforms(mode=1)\n","    test_ds = CSVClassificationDataset(TEST_CSV, TEST_IMG_DIR, transform=val_transform)\n","    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n","    num_images = len(test_ds)\n","    num_classes = test_ds.num_classes\n","    print(f\"Test set: {num_images} images, {num_classes} classes\")\n","\n","    # Load model and weights\n","    print(f\"Loading model weights from {MODEL_PATH}\")\n","    models_dict = dict(get_all_models(num_classes))\n","    model = models_dict[model_name]\n","    state = torch.load(MODEL_PATH, map_location=device)\n","    model.load_state_dict(state)\n","    model = model.to(device).eval()\n","\n","    # Warm-up\n","    print(\"Running warm-up pass…\")\n","    with torch.no_grad():\n","        imgs, _ = next(iter(test_loader))\n","        _ = model(imgs.to(device))\n","\n","    # Timing\n","    print(\"Timing full dataset inference…\")\n","    start = perf_counter()\n","    with torch.no_grad():\n","        for imgs, _ in test_loader:\n","            _ = model(imgs.to(device))\n","    end = perf_counter()\n","\n","    total_time = end - start\n","    avg_time   = total_time / num_images\n","    print(f\"Total time: {total_time:.2f}s for {num_images} images\")\n","    print(f\"Average per image: {avg_time:.4f}s\")\n","\n","    # Save results\n","    df_time = pd.DataFrame([{\n","        \"model\":       model_name,\n","        \"run_version\": run_version,\n","        \"num_images\":  num_images,\n","        \"total_time_s\": total_time,\n","        \"avg_time_s\":   avg_time\n","    }])\n","    output_csv = os.path.join(SAVE_DIR, \"cpu_inference_time.csv\")\n","    df_time.to_csv(output_csv, index=False)\n","    print(f\"Saved timing CSV to {output_csv}\\n\")\n","\n","    return df_time"],"metadata":{"id":"Zl0XwpsW28LX","executionInfo":{"status":"ok","timestamp":1752741883863,"user_tz":-480,"elapsed":1,"user":{"displayName":"FYP","userId":"06650288711143266396"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Main Testing Launcher"],"metadata":{"id":"muwlHeoCK7Zn"}},{"cell_type":"code","source":["if __name__ == '__main__':\n","    for model_name in [\"ResNet50\", \"EfficientNetB2\", \"MobileNetV3\"]:\n","      evaluate_model(model_name, run_version=\"run_v4\", model_filename=\"best.pth\")\n","      measure_cpu_inference_time(model_name, run_version=\"run_v4\", model_filename=\"best.pth\")\n"],"metadata":{"id":"i0U4ZGrlTmjF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752743262726,"user_tz":-480,"elapsed":1351625,"user":{"displayName":"FYP","userId":"06650288711143266396"}},"outputId":"2dfba526-f732-4908-d078-3602ef86dc5e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating ResNet50 (run_v4) ---\n","✅ Saved all evaluation outputs for ResNet50 to:\n"," → /content/drive/MyDrive/Brandon's FYP/ResNet50/run_v4\n","\n","--- CPU Inference Timing: ResNet50 (run_v4) ---\n","Loading test set from data/test/_classes.csv\n","Test set: 1824 images, 4 classes\n","Loading model weights from /content/drive/MyDrive/Brandon's FYP/ResNet50/run_v4/best.pth\n","Running warm-up pass…\n","Timing full dataset inference…\n","Total time: 595.57s for 1824 images\n","Average per image: 0.3265s\n","Saved timing CSV to /content/drive/MyDrive/Brandon's FYP/ResNet50/run_v4/cpu_inference_time.csv\n","\n","\n","--- Evaluating EfficientNetB2 (run_v4) ---\n","✅ Saved all evaluation outputs for EfficientNetB2 to:\n"," → /content/drive/MyDrive/Brandon's FYP/EfficientNetB2/run_v4\n","\n","--- CPU Inference Timing: EfficientNetB2 (run_v4) ---\n","Loading test set from data/test/_classes.csv\n","Test set: 1824 images, 4 classes\n","Loading model weights from /content/drive/MyDrive/Brandon's FYP/EfficientNetB2/run_v4/best.pth\n","Running warm-up pass…\n","Timing full dataset inference…\n","Total time: 165.02s for 1824 images\n","Average per image: 0.0905s\n","Saved timing CSV to /content/drive/MyDrive/Brandon's FYP/EfficientNetB2/run_v4/cpu_inference_time.csv\n","\n","\n","--- Evaluating MobileNetV3 (run_v4) ---\n","✅ Saved all evaluation outputs for MobileNetV3 to:\n"," → /content/drive/MyDrive/Brandon's FYP/MobileNetV3/run_v4\n","\n","--- CPU Inference Timing: MobileNetV3 (run_v4) ---\n","Loading test set from data/test/_classes.csv\n","Test set: 1824 images, 4 classes\n","Loading model weights from /content/drive/MyDrive/Brandon's FYP/MobileNetV3/run_v4/best.pth\n","Running warm-up pass…\n","Timing full dataset inference…\n","Total time: 485.32s for 1824 images\n","Average per image: 0.2661s\n","Saved timing CSV to /content/drive/MyDrive/Brandon's FYP/MobileNetV3/run_v4/cpu_inference_time.csv\n","\n"]}]},{"cell_type":"markdown","source":["# Auto Disconnect After Training"],"metadata":{"id":"IrekXjsjUzO8"}},{"cell_type":"code","source":["import time\n","from google.colab import runtime\n","\n","def disconnect_after(minutes=5):\n","    print(f\"Will disconnect Colab in {minutes} minutes if still running...\")\n","    time.sleep(minutes * 60)\n","    print(\"Disconnecting now.\")\n","    runtime.unassign()\n","\n","if __name__ == '__main__':\n","    disconnect_after(minutes=5)"],"metadata":{"id":"2gYp43gIUxWG","executionInfo":{"status":"ok","timestamp":1749491793486,"user_tz":-480,"elapsed":300233,"user":{"displayName":"FYP","userId":"06650288711143266396"}},"colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"e2b62ed1-a082-446b-e7aa-a7f0b7866340"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Will disconnect Colab in 5 minutes if still running...\n","Disconnecting now.\n"]}]}]}